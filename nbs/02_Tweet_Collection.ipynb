{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Tweet Collection\n",
    "\n",
    "Now that the accounts for examination have been assembled, it is time to collect all tweets for the years 2016 and 2017.\n",
    "Since the expected total size in JSON format exceeds two GB, it helpful to collect tweets in chunks.\n",
    "\n",
    "The following steps will be undertaken in this notebook:\n",
    "1. Setup API connection\n",
    "2. Load user IDs from file\n",
    "3. Test tweet collection process\n",
    "4. Collect and save tweets\n",
    "5. Sync data files to S3\n",
    "\n",
    "## Setup API connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Thu May 01 12:37:22 +0000 2014\", \"description\": \"Student of Information Systems @TUDarmstadt , co-founder of a small web agency. Interested in Machine Learning\", \"favourites_count\": 394, \"followers_count\": 58, \"friends_count\": 226, \"id\": 2472450259, \"id_str\": \"2472450259\", \"lang\": \"en\", \"listed_count\": 7, \"location\": \"Darmstadt, Deutschland\", \"name\": \"Felix Peters\", \"profile_background_color\": \"C0DEED\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/600953861629734913/7y_RkdW4_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/600953861629734913/7y_RkdW4_normal.jpg\", \"profile_link_color\": \"224F82\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"_fpeters\", \"status\": {\"created_at\": \"Sat May 26 15:47:34 +0000 2018\", \"id\": 1000403077093085192, \"id_str\": \"1000403077093085192\", \"lang\": \"en\", \"quoted_status_id\": 1000166112615714816, \"quoted_status_id_str\": \"1000166112615714816\", \"retweet_count\": 52, \"retweeted\": true, \"retweeted_status\": {\"created_at\": \"Sat May 26 11:38:56 +0000 2018\", \"favorite_count\": 81, \"id\": 1000340506189139968, \"id_str\": \"1000340506189139968\", \"lang\": \"en\", \"quoted_status_id\": 1000166112615714816, \"quoted_status_id_str\": \"1000166112615714816\", \"retweet_count\": 52, \"retweeted\": true, \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\", \"text\": \"\\u201cThey went from a load time of more than 45 seconds to 3 seconds, from 124 JavaScript files to 0, and from a total\\u2026 https://t.co/PsmSKdMqXt\", \"truncated\": true}, \"source\": \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\", \"text\": \"RT @aallan: \\u201cThey went from a load time of more than 45 seconds to 3 seconds, from 124 JavaScript files to 0, and from a total of more than\\u2026\"}, \"statuses_count\": 424, \"url\": \"https://t.co/KAhh0Hxkzm\"}\n"
     ]
    }
   ],
   "source": [
    "from tep.tweetCollector import TweetCollector\n",
    "tc = TweetCollector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Thu May 01 12:37:22 +0000 2014\", \"description\": \"Student of Information Systems @TUDarmstadt , co-founder of a small web agency. Interested in Machine Learning\", \"favourites_count\": 394, \"followers_count\": 58, \"friends_count\": 226, \"id\": 2472450259, \"id_str\": \"2472450259\", \"lang\": \"en\", \"listed_count\": 7, \"location\": \"Darmstadt, Deutschland\", \"name\": \"Felix Peters\", \"profile_background_color\": \"C0DEED\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/600953861629734913/7y_RkdW4_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/600953861629734913/7y_RkdW4_normal.jpg\", \"profile_link_color\": \"224F82\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"_fpeters\", \"status\": {\"created_at\": \"Sat May 26 15:47:34 +0000 2018\", \"id\": 1000403077093085192, \"id_str\": \"1000403077093085192\", \"lang\": \"en\", \"quoted_status_id\": 1000166112615714816, \"quoted_status_id_str\": \"1000166112615714816\", \"retweet_count\": 52, \"retweeted\": true, \"retweeted_status\": {\"created_at\": \"Sat May 26 11:38:56 +0000 2018\", \"favorite_count\": 81, \"id\": 1000340506189139968, \"id_str\": \"1000340506189139968\", \"lang\": \"en\", \"quoted_status_id\": 1000166112615714816, \"quoted_status_id_str\": \"1000166112615714816\", \"retweet_count\": 52, \"retweeted\": true, \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\", \"text\": \"\\u201cThey went from a load time of more than 45 seconds to 3 seconds, from 124 JavaScript files to 0, and from a total\\u2026 https://t.co/PsmSKdMqXt\", \"truncated\": true}, \"source\": \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\", \"text\": \"RT @aallan: \\u201cThey went from a load time of more than 45 seconds to 3 seconds, from 124 JavaScript files to 0, and from a total of more than\\u2026\"}, \"statuses_count\": 424, \"url\": \"https://t.co/KAhh0Hxkzm\"}\n"
     ]
    }
   ],
   "source": [
    "from tep.accountCollector import AccountCollector\n",
    "ac = AccountCollector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load user IDs from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 418, 586, 648, 989, 1081, 3980, 5699, 6204, 30973]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = ac.load_user_ids(fname=\"data/user_ids.txt\")\n",
    "user_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test tweet collection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup start and end date of examined period\n",
    "from datetime import datetime\n",
    "from tep.utils import *\n",
    "start = datetime(2018, 4, 1, 0, 0, 0, 000000, tzinfo=UTC())\n",
    "end = datetime(2018, 5, 1, 0, 0, 0, 000000, tzinfo=UTC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "Total tweets after 0 steps: 0\n",
      "Total tweets after 5 steps: 1,319\n",
      "Terminating data collection with total of 3246 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets = tc.get_tweets(user_ids=user_ids[:10], start=start, end=end, update_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_json(data=tweets, filename=\"data/tweet_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems to be working, so let's start the collection process...\n",
    "\n",
    "## Collect and save tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = datetime(2016, 4, 1, 0, 0, 0, 000000, tzinfo=UTC())\n",
    "end = datetime(2018, 4, 1, 0, 0, 0, 000000, tzinfo=UTC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "Total tweets after 0 steps: 0\n",
      "Total tweets after 10 steps: 21,867\n",
      "Total tweets after 20 steps: 44,934\n",
      "Total tweets after 30 steps: 65,732\n",
      "Total tweets after 40 steps: 88,971\n",
      "Total tweets after 50 steps: 102,383\n",
      "Total tweets after 60 steps: 115,205\n",
      "Total tweets after 70 steps: 135,308\n",
      "Total tweets after 80 steps: 161,749\n",
      "Total tweets after 90 steps: 178,241\n",
      "Total tweets after 100 steps: 198,941\n",
      "Total tweets after 110 steps: 214,739\n",
      "Total tweets after 120 steps: 228,332\n",
      "Total tweets after 130 steps: 241,661\n",
      "Total tweets after 140 steps: 260,685\n",
      "Total tweets after 150 steps: 282,792\n",
      "Total tweets after 160 steps: 303,918\n",
      "Total tweets after 170 steps: 320,964\n",
      "Total tweets after 180 steps: 342,600\n",
      "Total tweets after 190 steps: 356,153\n",
      "Terminating data collection with total of 379051 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets = tc.get_tweets(user_ids=user_ids[:200], start=start, end=end, update_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284701\n"
     ]
    }
   ],
   "source": [
    "tweets = [t for t in tweets if t.retweeted_status == None]\n",
    "total = len(tweets)\n",
    "print(total)\n",
    "save_as_json(data=tweets, filename=\"data/tweets_1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "Total tweets after 0 steps: 0\n",
      "Total tweets after 10 steps: 21,355\n",
      "Total tweets after 20 steps: 40,100\n",
      "Total tweets after 30 steps: 59,179\n",
      "Total tweets after 40 steps: 77,571\n",
      "Total tweets after 50 steps: 87,690\n",
      "Total tweets after 60 steps: 102,661\n",
      "Total tweets after 70 steps: 120,477\n",
      "Total tweets after 80 steps: 137,921\n",
      "Total tweets after 90 steps: 157,771\n",
      "Total tweets after 100 steps: 180,997\n",
      "Total tweets after 110 steps: 197,955\n",
      "Total tweets after 120 steps: 217,922\n",
      "Total tweets after 130 steps: 232,458\n",
      "Total tweets after 140 steps: 251,065\n",
      "Total tweets after 150 steps: 270,767\n",
      "Total tweets after 160 steps: 282,777\n",
      "Total tweets after 170 steps: 306,684\n",
      "Total tweets after 180 steps: 318,658\n",
      "Total tweets after 190 steps: 337,382\n",
      "Terminating data collection with total of 357057 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets = tc.get_tweets(user_ids=user_ids[200:400], start=start, end=end, update_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565486\n"
     ]
    }
   ],
   "source": [
    "tweets = [t for t in tweets if t.retweeted_status == None]\n",
    "total += len(tweets)\n",
    "print(total)\n",
    "save_as_json(data=tweets, filename=\"data/tweets_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "Total tweets after 0 steps: 0\n",
      "Total tweets after 10 steps: 13,427\n",
      "Total tweets after 20 steps: 26,004\n",
      "Total tweets after 30 steps: 41,426\n",
      "Total tweets after 40 steps: 52,578\n",
      "Total tweets after 50 steps: 69,819\n",
      "Total tweets after 60 steps: 86,659\n",
      "Total tweets after 70 steps: 104,218\n",
      "Total tweets after 80 steps: 117,268\n",
      "Total tweets after 90 steps: 125,569\n",
      "Total tweets after 100 steps: 140,319\n",
      "Total tweets after 110 steps: 152,975\n",
      "Total tweets after 120 steps: 172,634\n",
      "Total tweets after 130 steps: 185,480\n",
      "Total tweets after 140 steps: 196,395\n",
      "Total tweets after 150 steps: 215,756\n",
      "Total tweets after 160 steps: 233,264\n",
      "Total tweets after 170 steps: 250,523\n",
      "Total tweets after 180 steps: 265,658\n",
      "Total tweets after 190 steps: 279,886\n",
      "Terminating data collection with total of 288532 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets = tc.get_tweets(user_ids=user_ids[400:600], start=start, end=end, update_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781721\n"
     ]
    }
   ],
   "source": [
    "tweets = [t for t in tweets if t.retweeted_status == None]\n",
    "total += len(tweets)\n",
    "print(total)\n",
    "save_as_json(data=tweets, filename=\"data/tweets_3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "Total tweets after 0 steps: 0\n",
      "Total tweets after 10 steps: 15,907\n",
      "Total tweets after 20 steps: 28,505\n",
      "Total tweets after 30 steps: 48,975\n",
      "Total tweets after 40 steps: 70,384\n",
      "Total tweets after 50 steps: 86,282\n",
      "Total tweets after 60 steps: 101,434\n",
      "Total tweets after 70 steps: 123,134\n",
      "Total tweets after 80 steps: 142,955\n",
      "Total tweets after 90 steps: 159,548\n",
      "Total tweets after 100 steps: 168,219\n",
      "Total tweets after 110 steps: 190,111\n",
      "Total tweets after 120 steps: 210,322\n",
      "Total tweets after 130 steps: 221,961\n",
      "Total tweets after 140 steps: 234,095\n",
      "Total tweets after 150 steps: 248,300\n",
      "Total tweets after 160 steps: 263,502\n",
      "Total tweets after 170 steps: 278,086\n",
      "Total tweets after 180 steps: 296,363\n",
      "Total tweets after 190 steps: 311,215\n",
      "Terminating data collection with total of 325955 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets = tc.get_tweets(user_ids=user_ids[600:800], start=start, end=end, update_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031077\n"
     ]
    }
   ],
   "source": [
    "tweets = [t for t in tweets if t.retweeted_status == None]\n",
    "total += len(tweets)\n",
    "print(total)\n",
    "save_as_json(data=tweets, filename=\"data/tweets_4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "Total tweets after 0 steps: 0\n",
      "Total tweets after 10 steps: 13,203\n",
      "Total tweets after 20 steps: 24,640\n",
      "Total tweets after 30 steps: 39,746\n",
      "Total tweets after 40 steps: 59,006\n",
      "Total tweets after 50 steps: 70,112\n",
      "Total tweets after 60 steps: 87,519\n",
      "Total tweets after 70 steps: 97,802\n",
      "Total tweets after 80 steps: 111,791\n",
      "Total tweets after 90 steps: 124,724\n",
      "Total tweets after 100 steps: 138,694\n",
      "Total tweets after 110 steps: 156,747\n",
      "Total tweets after 120 steps: 171,071\n",
      "Total tweets after 130 steps: 184,987\n",
      "Total tweets after 140 steps: 198,662\n",
      "Total tweets after 150 steps: 208,381\n",
      "Total tweets after 160 steps: 215,515\n",
      "Total tweets after 170 steps: 232,338\n",
      "Error occurred when collecting tweets for user 1056152593\n",
      "Total tweets after 180 steps: 252,377\n",
      "Total tweets after 190 steps: 263,766\n",
      "Total tweets after 200 steps: 272,172\n",
      "Total tweets after 210 steps: 284,723\n",
      "Total tweets after 220 steps: 295,190\n",
      "Total tweets after 230 steps: 302,807\n",
      "Total tweets after 240 steps: 310,771\n",
      "Total tweets after 250 steps: 318,700\n",
      "Total tweets after 260 steps: 326,635\n",
      "Terminating data collection with total of 326833 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets = tc.get_tweets(user_ids=user_ids[800:], start=start, end=end, update_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293005\n"
     ]
    }
   ],
   "source": [
    "tweets = [t for t in tweets if t.retweeted_status == None]\n",
    "total += len(tweets)\n",
    "print(total)\n",
    "save_as_json(data=tweets, filename=\"data/tweets_5.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync data files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-30 09:05:02 tep-research-project\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/felix/code/ml/tweet-engagement-prediction/nbs'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/tech_accounts.txt to s3://tep-research-project/tech_accounts.txt      \n",
      "upload: data/journalist_accounts.txt to s3://tep-research-project/journalist_accounts.txt\n",
      "upload: data/celebrity_accounts.txt to s3://tep-research-project/celebrity_accounts.txt\n",
      "upload: data/user_ids.txt to s3://tep-research-project/user_ids.txt              \n",
      "upload: data/tweets_2.json to s3://tep-research-project/tweets_2.json\n",
      "upload: data/tweets_4.json to s3://tep-research-project/tweets_4.json\n",
      "upload: data/tweets_3.json to s3://tep-research-project/tweets_3.json\n",
      "upload: data/tweets_1.json to s3://tep-research-project/tweets_1.json\n",
      "upload: data/tweets_5.json to s3://tep-research-project/tweets_5.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync data/ s3://tep-research-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
