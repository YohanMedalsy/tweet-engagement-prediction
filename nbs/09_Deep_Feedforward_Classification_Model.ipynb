{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from tep.config import Config\n",
    "config = Config()\n",
    "classes = config.CLASSES\n",
    "num_classes = len(classes) + 1\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1293005, 15)\n",
      "(1293005,)\n"
     ]
    }
   ],
   "source": [
    "from tep.utils import load_array\n",
    "features = load_array(filename=\"data/auxiliary_features.bc\")\n",
    "labels = load_array(filename=\"data/classification_labels.bc\")\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1293005, 5)\n"
     ]
    }
   ],
   "source": [
    "from tep.trainUtils import one_hot_encoding\n",
    "oh_labels = one_hot_encoding(class_labels=labels, number_classes=num_classes)\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define configurations to test\n",
    "configs = [\n",
    "    {'name': '1h_16n', 'num_layers': 1, 'num_units': 16},\n",
    "    {'name': '1h_32n', 'num_layers': 1, 'num_units': 32},\n",
    "    {'name': '1h_64n', 'num_layers': 1, 'num_units': 64},\n",
    "    {'name': '2h_16n', 'num_layers': 2, 'num_units': 16},\n",
    "    {'name': '2h_32n', 'num_layers': 2, 'num_units': 32},\n",
    "    {'name': '2h_64n', 'num_layers': 2, 'num_units': 64},\n",
    "    {'name': '3h_16n', 'num_layers': 3, 'num_units': 16},\n",
    "    {'name': '3h_32n', 'num_layers': 3, 'num_units': 32},\n",
    "    {'name': '3h_64n', 'num_layers': 3, 'num_units': 64},\n",
    "    {'name': '4h_16n', 'num_layers': 4, 'num_units': 16},\n",
    "    {'name': '4h_32n', 'num_layers': 4, 'num_units': 32},\n",
    "    {'name': '4h_64n', 'num_layers': 4, 'num_units': 64},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use settings for testing on sample\n",
    "train_size = 10000\n",
    "val_size = 1000\n",
    "batch_size = 64\n",
    "\n",
    "# use settings for running on full data\n",
    "#val_size = 10000\n",
    "#train_size = features.shape[0] - val_size\n",
    "#batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_name = 'dffn_class'\n",
    "root_path = 'models/' + root_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: dffn_class_1h_16n\n",
      "Training set: 10000 examples\n",
      "Validation set: 1000 examples\n",
      "Epoch 00001: val_loss improved from inf to 1.30864, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00002: val_loss improved from 1.30864 to 1.17916, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00003: val_loss improved from 1.17916 to 1.12749, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00004: val_loss improved from 1.12749 to 1.10112, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00005: val_loss improved from 1.10112 to 1.08547, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00006: val_loss improved from 1.08547 to 1.06912, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00007: val_loss improved from 1.06912 to 1.05105, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00008: val_loss improved from 1.05105 to 1.04743, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 00010: val_loss improved from 1.04743 to 1.04715, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 00012: val_loss improved from 1.04715 to 1.04658, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00013: val_loss improved from 1.04658 to 1.00535, saving model to models/dffn_class_1h_16n.hdf5\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 00019: val_loss did not improve\n",
      "\n",
      "Epoch 00019: reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 00023: early stopping\n",
      "loss: 0.9751832618713379, acc: 0.5788, val_loss: 1.005351620197296, val_acc: 0.5649999995231628\n",
      "\n",
      "\n",
      "Start training model: dffn_class_1h_32n\n",
      "Training set: 10000 examples\n",
      "Validation set: 1000 examples\n",
      "Epoch 00001: val_loss improved from inf to 1.23506, saving model to models/dffn_class_1h_32n.hdf5\n",
      "Epoch 00002: val_loss improved from 1.23506 to 1.13537, saving model to models/dffn_class_1h_32n.hdf5\n",
      "Epoch 00003: val_loss improved from 1.13537 to 1.09142, saving model to models/dffn_class_1h_32n.hdf5\n",
      "Epoch 00004: val_loss improved from 1.09142 to 1.06467, saving model to models/dffn_class_1h_32n.hdf5\n",
      "Epoch 00005: val_loss improved from 1.06467 to 1.04800, saving model to models/dffn_class_1h_32n.hdf5\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00007: val_loss improved from 1.04800 to 1.01934, saving model to models/dffn_class_1h_32n.hdf5\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 00009: val_loss improved from 1.01934 to 1.01242, saving model to models/dffn_class_1h_32n.hdf5\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 00011: val_loss improved from 1.01242 to 0.99930, saving model to models/dffn_class_1h_32n.hdf5\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 00017: val_loss did not improve\n",
      "\n",
      "Epoch 00017: reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 00021: early stopping\n",
      "loss: 0.9610043663024902, acc: 0.58, val_loss: 0.9993015327453614, val_acc: 0.5779999990463257\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tep.deepFeedforwardNetwork import classification_model\n",
    "from tep.modelUtils import save_architecture\n",
    "from tep.trainUtils import get_callbacks, print_classification_metrics\n",
    "\n",
    "for config in configs[:2]:\n",
    "    # clear tf session first in order to avoid conflicts\n",
    "    K.clear_session()\n",
    "\n",
    "    # set model path\n",
    "    model_name = root_name + '_' + config['name']\n",
    "    model_path = root_path + '_' + config['name']\n",
    "    logging_path = root_path + '/' + config['name']\n",
    "    \n",
    "    # Start logging\n",
    "    print(\"Start training model: \" + model_name)\n",
    "    print(\"Training set: {} examples\".format(train_size))\n",
    "    print(\"Validation set: {} examples\".format(val_size))\n",
    "    \n",
    "    # Create logging directory\n",
    "    !mkdir -p $logging_path\n",
    "    # Remove prior logs\n",
    "    !rm $logging_path/*\n",
    "    \n",
    "    # load and save model\n",
    "    model = classification_model(features.shape[1], num_classes, config['num_layers'], config['num_units'])\n",
    "    save_architecture(model, model_path + '.json')\n",
    "    \n",
    "    # load model callbacks\n",
    "    cbs = get_callbacks(model_name=model_name, log_dir=logging_path, verbose=1)\n",
    "    \n",
    "    # train model\n",
    "    model.fit(features[:train_size], \n",
    "          oh_labels[:train_size], \n",
    "          validation_data=(features[-val_size:], oh_labels[-val_size:]), \n",
    "          batch_size=batch_size, \n",
    "          epochs=100, \n",
    "          verbose=0,\n",
    "          shuffle=True,\n",
    "          callbacks=cbs)\n",
    "    \n",
    "    # print best result\n",
    "    history = cbs[2]\n",
    "    print_classification_metrics(history)\n",
    "    \n",
    "    # add newline after model was trained\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
