{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with enhanced meta features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auxiliary_features.bc\t       journalist_accounts.txt\ttweets_1.json\r\n",
      "auxiliary_features_v2.bc       log_labels_v3.bc\t\ttweets_2.json\r\n",
      "celebrity_accounts.txt\t       meta_features_v3.bc\ttweets_3.json\r\n",
      "classification_labels.bc       raw_labels_v3.bc\t\ttweets_4.json\r\n",
      "classification_labels_v2.bc    regression_labels.bc\ttweets_5.json\r\n",
      "embedding_matrix_100dim.bc     regression_labels_v2.bc\ttweet_texts.txt\r\n",
      "embedding_matrix_100dim_v2.bc  sentiment_data\t\ttweet_texts_v2.txt\r\n",
      "embedding_matrix_100dim_v3.bc  sequences_len32.bc\ttweet_texts_v3.txt\r\n",
      "embedding_matrix_200dim.bc     sequences_len32_v2.bc\tuser_ids.txt\r\n",
      "embedding_matrix_200dim_v2.bc  sequences_len32_v3.bc\tword_index.json\r\n",
      "embedding_matrix_25dim.bc      sequences_len48.bc\tword_index_v3.json\r\n",
      "embedding_matrix_25dim_v2.bc   sequences_len48_v2.bc\tword_labels.tsv\r\n",
      "embedding_matrix_50dim.bc      sequences_len48_v3.bc\tword_labels_v3.tsv\r\n",
      "embedding_matrix_50dim_v2.bc   tech_accounts.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1293005,)\n",
      "(1293005, 32)\n",
      "(1293005, 24)\n",
      "(721696, 100)\n"
     ]
    }
   ],
   "source": [
    "from tep.utils import load_array\n",
    "y = load_array(\"data/log_labels_v3.bc\")\n",
    "print(y.shape)\n",
    "X_seq = load_array(\"data/sequences_len32_v3.bc\")\n",
    "print(X_seq.shape)\n",
    "X_meta = load_array(\"data/meta_features_v3.bc\")\n",
    "print(X_meta.shape)\n",
    "emb_mat = load_array(\"data/embedding_matrix_100dim_v3.bc\")\n",
    "print(emb_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 1.],\n",
       "       [0., 0., 2., ..., 0., 0., 1.],\n",
       "       [0., 0., 2., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 3., 0., ..., 0., 0., 0.],\n",
       "       [1., 3., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 5., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.nan_to_num(X_meta, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tep.deepConvModel import regression_model\n",
    "from tep.trainUtils import get_callbacks, print_regression_metrics, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paperspace/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "model = regression_model(X_meta.shape[1], \n",
    "                         emb_mat, \n",
    "                         X_seq.shape[1], \n",
    "                         conv_layers=2, \n",
    "                         filters=64,\n",
    "                         dropout=0.5,\n",
    "                         fc_layers=2, \n",
    "                         fc_units=128, \n",
    "                         metrics=[r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_input (InputLayer)         (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_embedding (Embedding)      (None, 32, 100)      72169600    text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pad_1 (ZeroPadding1D)           (None, 34, 100)      0           word_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv1D)                 (None, 32, 64)       19264       pad_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool_1 (MaxPooling1D)           (None, 16, 64)       0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pad_2 (ZeroPadding1D)           (None, 18, 64)       0           pool_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv1D)                 (None, 16, 64)       12352       pad_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool_2 (MaxPooling1D)           (None, 8, 64)        0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 8, 64)        0           pool_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_aux (BatchNormalization)     (None, 24)           96          aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "comb_input (Concatenate)        (None, 536)          0           flatten[0][0]                    \n",
      "                                                                 bn_aux[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "fc_1 (Dense)                    (None, 128)          68736       comb_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn_1 (BatchNormalization)       (None, 128)          512         fc_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc_2 (Dense)                    (None, 128)          16512       bn_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bn_2 (BatchNormalization)       (None, 128)          512         fc_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            129         bn_2[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 72,287,713\n",
      "Trainable params: 72,287,153\n",
      "Non-trainable params: 560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/enhanced_meta'\n",
    "model_name = 'baseline'\n",
    "logging_path = model_path + '/' + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $logging_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/word_labels_v3.tsv $logging_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tep.modelUtils import save_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_architecture(model, model_path + '/' + model_name + '.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, History, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_file = model_path + '/' + model_name + '.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks\n",
    "cp = ModelCheckpoint(cp_file, save_best_only=True, save_weights_only=True, verbose=1)\n",
    "hist = History()\n",
    "es = EarlyStopping(patience=5, verbose=1)\n",
    "rlr = ReduceLROnPlateau(patience=3, verbose=1)\n",
    "cbs = [cp, hist, es, rlr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "1283005\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "valid_size = 10000\n",
    "train_size = X_seq.shape[0] - valid_size # 10000\n",
    "batch_size = 1024\n",
    "print(valid_size)\n",
    "print(train_size)\n",
    "print(batch_size)\n",
    "\n",
    "X_train = {'text_input': X_seq[:train_size], 'aux_input': X_meta[:train_size]}\n",
    "y_train = {'output': y[:train_size]}\n",
    "valid = ({'text_input': X_seq[-valid_size:], 'aux_input': X_meta[-valid_size:]}, {'output': y[-valid_size:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.89532, saving model to models/enhanced_meta/baseline.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.89532 to 0.80877, saving model to models/enhanced_meta/baseline.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.80877 to 0.80638, saving model to models/enhanced_meta/baseline.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.80638 to 0.78542, saving model to models/enhanced_meta/baseline.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f179045da58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=[r2])\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          validation_data=valid, \n",
    "          batch_size=batch_size, \n",
    "          verbose=0,\n",
    "          epochs=100,\n",
    "          shuffle=True, \n",
    "          callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6713629767480636, r2: 0.8528450812839237, val_loss: 0.7854210567474366, val_r2: 0.8265550698280334\n"
     ]
    }
   ],
   "source": [
    "history = cbs[1]\n",
    "print_regression_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline  baseline.hdf5  baseline.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls models/enhanced_meta/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze neuron activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/enhanced_meta/baseline.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "word_index_file = open('data/word_index_v3.json')\n",
    "word_index_str = word_index_file.read()\n",
    "word_index = json.loads(word_index_str)\n",
    "type(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tep.featureVisualization import ConvLayerVisualizer\n",
    "clv = ConvLayerVisualizer(model, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'text_input:0' shape=(?, 32) dtype=int32>,\n",
       " <tf.Tensor 'aux_input:0' shape=(?, 24) dtype=float32>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
