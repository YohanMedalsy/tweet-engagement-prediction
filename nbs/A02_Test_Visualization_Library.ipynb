{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_input (InputLayer)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         (None, 32, 100)           43224100  \n",
      "_________________________________________________________________\n",
      "input_dropout (Dropout)      (None, 32, 100)           0         \n",
      "_________________________________________________________________\n",
      "padding_1 (ZeroPadding1D)    (None, 34, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, 32, 128)           38528     \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling1D)        (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "padding_2 (ZeroPadding1D)    (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv1D)              (None, 16, 128)           49280     \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling1D)        (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "padding_3 (ZeroPadding1D)    (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv1D)              (None, 8, 128)            49280     \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling1D)        (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 43,427,110\n",
      "Trainable params: 43,427,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model architecture\n",
    "from tep.modelUtils import load_architecture\n",
    "model = load_architecture('models/tl/baseline.json')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set model weights\n",
    "model.load_weights('models/tl/baseline.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 32)\n",
      "(1600000,)\n"
     ]
    }
   ],
   "source": [
    "# load data and labels\n",
    "from tep.utils import load_array\n",
    "seqs = load_array('data/sentiment_data/seq_32.bc')\n",
    "labels = load_array('data/sentiment_data/labels.bc')\n",
    "print(seqs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load word index\n",
    "import json\n",
    "word_index_file = open('data/sentiment_data/word_index.json')\n",
    "word_index_str = word_index_file.read()\n",
    "word_index = json.loads(word_index_str)\n",
    "type(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 218us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34918261456489563, 0.84550000000000003]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model\n",
    "from tep.trainUtils import one_hot_encoding\n",
    "oh_labels = one_hot_encoding(labels, 2)\n",
    "model.evaluate(x=seqs[:10000], y=oh_labels[:10000], batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tep.featureVisualization import ConvLayerVisualizer\n",
    "clv = ConvLayerVisualizer(model, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 3.8374364,\n",
       "  'kernel': 33,\n",
       "  'position': 27,\n",
       "  'words': 'people smile in'},\n",
       " {'activation': 3.7581553,\n",
       "  'kernel': 100,\n",
       "  'position': 27,\n",
       "  'words': 'people smile in'},\n",
       " {'activation': 3.5078483,\n",
       "  'kernel': 23,\n",
       "  'position': 27,\n",
       "  'words': 'people smile in'},\n",
       " {'activation': 3.1374555,\n",
       "  'kernel': 57,\n",
       "  'position': 27,\n",
       "  'words': 'people smile in'},\n",
       " {'activation': 2.9925666,\n",
       "  'kernel': 64,\n",
       "  'position': 27,\n",
       "  'words': 'people smile in'},\n",
       " {'activation': 2.9566913,\n",
       "  'kernel': 9,\n",
       "  'position': 27,\n",
       "  'words': 'people smile in'},\n",
       " {'activation': 2.9120924,\n",
       "  'kernel': 84,\n",
       "  'position': 26,\n",
       "  'words': 'all people smile'},\n",
       " {'activation': 2.8235338,\n",
       "  'kernel': 65,\n",
       "  'position': 27,\n",
       "  'words': 'people smile in'},\n",
       " {'activation': 2.5399656,\n",
       "  'kernel': 34,\n",
       "  'position': 28,\n",
       "  'words': 'smile in the'},\n",
       " {'activation': 2.4670651,\n",
       "  'kernel': 127,\n",
       "  'position': 28,\n",
       "  'words': 'smile in the'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clv.analyze_example(seqs[2528], 'conv_1', num_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 3.7581553,\n",
       "  'kernel': 100,\n",
       "  'position': 27,\n",
       "  'tweet': 2528,\n",
       "  'words': 'people smile in'},\n",
       " {'activation': 3.5496619,\n",
       "  'kernel': 100,\n",
       "  'position': 17,\n",
       "  'tweet': 473,\n",
       "  'words': \"i'm smiling !\"},\n",
       " {'activation': 3.4549849,\n",
       "  'kernel': 100,\n",
       "  'position': 5,\n",
       "  'tweet': 5774,\n",
       "  'words': 'me smile .'},\n",
       " {'activation': 3.4549849,\n",
       "  'kernel': 100,\n",
       "  'position': 30,\n",
       "  'tweet': 339,\n",
       "  'words': 'me smile .'},\n",
       " {'activation': 3.4549849,\n",
       "  'kernel': 100,\n",
       "  'position': 30,\n",
       "  'tweet': 7330,\n",
       "  'words': 'me smile .'},\n",
       " {'activation': 3.4424214,\n",
       "  'kernel': 100,\n",
       "  'position': 21,\n",
       "  'tweet': 3433,\n",
       "  'words': '. thanks all'},\n",
       " {'activation': 3.4394569,\n",
       "  'kernel': 100,\n",
       "  'position': 27,\n",
       "  'tweet': 9436,\n",
       "  'words': '. glad it'},\n",
       " {'activation': 3.3911629,\n",
       "  'kernel': 100,\n",
       "  'position': 28,\n",
       "  'tweet': 3419,\n",
       "  'words': '. thankyouu <allcaps>'},\n",
       " {'activation': 3.3829739,\n",
       "  'kernel': 100,\n",
       "  'position': 31,\n",
       "  'tweet': 6999,\n",
       "  'words': 'me smile <unknown>'},\n",
       " {'activation': 3.3829739,\n",
       "  'kernel': 100,\n",
       "  'position': 31,\n",
       "  'tweet': 8766,\n",
       "  'words': 'me smile <unknown>'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clv.analyze_neuron(seqs[:10000], 'conv_1', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepexplain.tensorflow import DeepExplain\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'word_emb/Gather:0' shape=(?, 32, 100) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "    # Need to reconstruct the graph in DeepExplain context, using the same weights.\n",
    "    # With Keras this is very easy:\n",
    "    # 1. Get the input tensor to the original model\n",
    "    input_tensor = model.layers[2].input\n",
    "    \n",
    "    # 2. We now target the output of the last dense layer (pre-softmax)\n",
    "    # To do so, create a new model sharing the same layers untill the last dense (index -2)\n",
    "    fModel = Model(inputs=input_tensor, outputs = model.output)\n",
    "    target_tensor = fModel(input_tensor)\n",
    "    \n",
    "    xs = x_test[0:10]\n",
    "    ys = y_test[0:10]\n",
    "    \n",
    "    attributions = de.explain('grad*input', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('saliency', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('intgrad', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('deeplift', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('elrp', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('occlusion', target_tensor * ys, input_tensor, xs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
