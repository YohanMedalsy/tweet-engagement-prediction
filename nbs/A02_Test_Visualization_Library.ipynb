{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq_input (InputLayer)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         (None, 32, 100)           43224100  \n",
      "_________________________________________________________________\n",
      "input_dropout (Dropout)      (None, 32, 100)           0         \n",
      "_________________________________________________________________\n",
      "padding_1 (ZeroPadding1D)    (None, 34, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, 32, 128)           38528     \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling1D)        (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "padding_2 (ZeroPadding1D)    (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv1D)              (None, 16, 128)           49280     \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling1D)        (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "padding_3 (ZeroPadding1D)    (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv1D)              (None, 8, 128)            49280     \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling1D)        (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "raw_predictions (Dense)      (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "predictions (Activation)     (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 43,427,110\n",
      "Trainable params: 43,427,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model architecture\n",
    "from tep.modelUtils import load_architecture\n",
    "model = load_architecture('models/tl/baseline.json')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set model weights\n",
    "model.load_weights('models/tl/baseline.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 32)\n",
      "(1600000,)\n"
     ]
    }
   ],
   "source": [
    "# load data and labels\n",
    "from tep.utils import load_array\n",
    "seqs = load_array('data/sentiment_data/seq_32.bc')\n",
    "labels = load_array('data/sentiment_data/labels.bc')\n",
    "print(seqs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load word index\n",
    "import json\n",
    "word_index_file = open('data/sentiment_data/word_index.json')\n",
    "word_index_str = word_index_file.read()\n",
    "word_index = json.loads(word_index_str)\n",
    "type(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 224us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34807548885345457, 0.84930000000000005]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model\n",
    "from tep.trainUtils import one_hot_encoding\n",
    "oh_labels = one_hot_encoding(labels, 2)\n",
    "model.evaluate(x=seqs[:10000], y=oh_labels[:10000], batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tep.featureVisualization import ConvLayerVisualizer\n",
    "clv = ConvLayerVisualizer(model, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 2.4065974,\n",
       "  'kernel': 97,\n",
       "  'position': 29,\n",
       "  'words': 'my birthday on'},\n",
       " {'activation': 1.8522719,\n",
       "  'kernel': 113,\n",
       "  'position': 28,\n",
       "  'words': \"me,it's my birthday\"},\n",
       " {'activation': 1.6997725,\n",
       "  'kernel': 8,\n",
       "  'position': 30,\n",
       "  'words': 'birthday on monday'},\n",
       " {'activation': 1.6873175,\n",
       "  'kernel': 54,\n",
       "  'position': 29,\n",
       "  'words': 'my birthday on'},\n",
       " {'activation': 1.6785334,\n",
       "  'kernel': 62,\n",
       "  'position': 31,\n",
       "  'words': 'on monday <unknown>'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clv.analyze_example(seqs[0], 'conv_1', num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 3.0778136,\n",
       "  'kernel': 58,\n",
       "  'position': 28,\n",
       "  'tweet': 2889,\n",
       "  'words': 'twitter ! congrats'},\n",
       " {'activation': 3.0098078,\n",
       "  'kernel': 58,\n",
       "  'position': 19,\n",
       "  'tweet': 9192,\n",
       "  'words': 'twitters ! mwahh'},\n",
       " {'activation': 2.7932086,\n",
       "  'kernel': 58,\n",
       "  'position': 31,\n",
       "  'tweet': 9179,\n",
       "  'words': 'inari ! <unknown>'},\n",
       " {'activation': 2.7836375,\n",
       "  'kernel': 58,\n",
       "  'position': 17,\n",
       "  'tweet': 9408,\n",
       "  'words': 'angekommen morgen wieder'},\n",
       " {'activation': 2.7572386,\n",
       "  'kernel': 58,\n",
       "  'position': 31,\n",
       "  'tweet': 5683,\n",
       "  'words': 'facebook ! <unknown>'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clv.analyze_neuron(seqs[:10000], 'conv_1', 58, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "x_test = seqs[-10000:]\n",
    "y_test = oh_labels[-10000:]\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_input_attributions(model, weights, target_layer, output_layer, x, y, method='elrp'):\n",
    "    current_session = K.get_session()\n",
    "    \n",
    "    with DeepExplain(session=current_session) as de:\n",
    "        model = load_architecture(model)\n",
    "        model.load_weights(weights)\n",
    "        model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "        \n",
    "        target = model.get_layer(target_layer).output\n",
    "        input_tensor = model.inputs[0]\n",
    "        target_out = current_session.run(target, {input_tensor: x})\n",
    "        output_tensor = model.get_layer(output_layer).output\n",
    "        \n",
    "        attributions = de.explain(method, output_tensor * y, target, target_out)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'models/tl/baseline.json'\n",
    "weights_path = 'models/tl/baseline.hdf5'\n",
    "target = 'word_emb'\n",
    "output = 'raw_predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepExplain: running \"elrp\" explanation method (4)\n",
      "Model with multiple inputs:  False\n",
      "(10000, 32, 100)\n"
     ]
    }
   ],
   "source": [
    "attributions = calculate_input_attributions(model_path, weights_path, target, output, x_test, y_test)\n",
    "print(attributions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.28994\n",
      "-4.46913\n",
      "0.0259702\n"
     ]
    }
   ],
   "source": [
    "attributions = attributions.sum(axis=-1)\n",
    "print(attributions.max())\n",
    "print(attributions.min())\n",
    "print(attributions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "def calculate_hidden_attributions(model, weights, target_layer, output_layer, x, y, method='elrp'):\n",
    "    current_session = K.get_session()\n",
    "    \n",
    "    with DeepExplain(session=current_session) as de:\n",
    "        # load original model\n",
    "        model = load_architecture(model)\n",
    "        model.load_weights(weights)\n",
    "        model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "        \n",
    "        # calculate activations for target_layer\n",
    "        tmp_model = Model(inputs=model.input, outputs=model.layers[target_layer].output)\n",
    "        target_outputs = tmp_model.predict(x)\n",
    "\n",
    "        # generate new model\n",
    "        new_input = Input(shape=model.layers[target_layer].output_shape, name='new_input')\n",
    "        config = model.get_config()\n",
    "        config['input_layers'] = [['new_input']]\n",
    "            \n",
    "        model.layers[target_layer+1].input = new_input\n",
    "        model_copy.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-bb6cb28f790b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'raw_predictions'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcalculate_hidden_attributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-97-8d1e3fb37775>\u001b[0m in \u001b[0;36mcalculate_hidden_attributions\u001b[0;34m(model, weights, target_layer, output_layer, x, y, method)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnew_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mmodel_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "model_path = 'models/tl/baseline.json'\n",
    "weights_path = 'models/tl/baseline.hdf5'\n",
    "target = 4\n",
    "output = 'raw_predictions'\n",
    "\n",
    "calculate_hidden_attributions(model_path, weights_path, target, output, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['seq_input', 0, 0]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['input_layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer = model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_input_shape': (None, 32),\n",
       " 'dtype': 'int32',\n",
       " 'name': 'seq_input',\n",
       " 'sparse': False}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(config['layers'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
